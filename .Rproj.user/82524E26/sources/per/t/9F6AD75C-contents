---
title: "Meta-analysis in Plant Pathology"
format: 
  html:
    toc: true
editor: visual
editor_options: 
  chunk_output_type: console
---

```{r}
#| echo: false
#| warning: false
#| message: false

library(tidyverse)
library(gsheet)
library(janitor)
library(ggthemes)
library(cowplot)
library(colorspace)
library(patchwork)
library(wordcloud)
```

```{r}
dat <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1vYXB1Ag-ouLgo9nLIelP1V0hz-ki0f7p-aOCAkmuxKI/edit#gid=1058316481")
theme_set(theme_minimal_grid())
```

# Bibliographic info

## Total number of pubs

```{r}
nrow(dat)

dat |> 
  tabyl(article_type)

```

## Pub type by year

```{r}
p1 <- dat %>% 
  tabyl(pub_year, article_type) %>% 
  pivot_longer(names_to = "Type", 
               values_to = "n", 2:3) %>% 
  ggplot(aes(pub_year, n, fill = Type))+
 geom_col()+
  scale_x_continuous(breaks = c(1999, 2001, 2004, 2007, 2010, 2013, 2016,
                                2019, 2022))+
  theme(legend.position = "bottom",
          panel.grid.major=element_line(colour="grey94"))+
 scale_fill_discrete_qualitative(palette = "cold")+
  scale_y_continuous(n.breaks = 10)+
  labs( x = "Publication year", y = "Number of publications")


```

## Journals

```{r}
tab2 <- dat %>% 
  dplyr::select(journal) %>% 
   tabyl(journal) %>% 
  select(-percent) |> 
  arrange(-n)

tab2

```

```{r}
#| fig-width: 14
#| fig-height: 7
set.seed(1)
old_par <- par(mar = c(0, 2, 0, 0), bg = NA)
p1 + wrap_elements(panel = ~wordcloud(words = tab2$journal, freq = tab2$n,  min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.25, colors=brewer.pal(6, "Dark2")))
par(old_par)
ggsave("figs/figure1.png", width = 14, height = 7, bg = "white")


```

## Number of authors per publication

```{r}
dat %>% 
  tabyl(n_authors) 

dat |> 
  tabyl(n_authors) |> 
  summary()

```

## Unique authors

```{r}

dat_authors <- gsheet2tbl("https://docs.google.com/spreadsheets/d/1vYXB1Ag-ouLgo9nLIelP1V0hz-ki0f7p-aOCAkmuxKI/edit#gid=1102752782")
authors <- dat_authors %>% 
  gather(author, name, 2:32) %>% 
  select(author, name) %>% 
  filter(name != "NA") %>% 
  group_by(name) %>% 
  tally(sort = T) 


```

## Authorship network

```{r}
library(purrr)
library(purrrlyr)

authors_net <- dat_authors %>% select (2:32)
author_list <- flatten(by_row(authors_net, ..f = function(x) flatten_chr(x), .labels = FALSE))
author_list <- lapply(author_list, function(x) x[!is.na(x)])

# create the edge list
author_edge_list <- t(do.call(cbind, lapply(author_list[sapply(author_list, length) >= 2], combn, 2)))

author_edge_list[1:10, ]





```

Within an authorship network, co-authors (present in a same article) are linked together. Authors from this articles can be connected to authors from other articles whenever they appear together. Therefore, two articles are linked by a common author. Each author is then considered a **node** in the network and the connections between them are the **edges** or links. There are several statistics to calculate in a network analysis.

For now, let's visualize the authorship network and also the community structure which was defined via a function that tries to find densely connected subgraphs, also called communities. We will use a random walk algorithm for determining the communities. The idea is that short random walks tend to stay in the same community. In the network below, the subgraphs are represented by the colors.

```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
# igraph
library(igraph)
net=graph.edgelist(as.matrix(author_edge_list), directed=FALSE)

degree <- enframe(degree(net))


degree %>% 
  arrange(-value)

#summary(degree$degree.net.)
between <- data.frame(round(betweenness(net), 1))
page <- data.frame(page_rank(net)$vector)
close <-data.frame(round(closeness(net), 10))
eigen <- data.frame(round(evcent(net)$vector, 5))

between |> 
  head(20) |> 
  arrange(- round.betweenness.net...1.)

```

### Network graph

```{r cache=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
library(network)
library(intergraph)

# Clusters
wc <- cluster_walktrap(net)
eb <- cluster_edge_betweenness(net)
lec <- cluster_leading_eigen(net)
cl <- cluster_label_prop(net)

# Modularity
mod <- modularity(wc)
ms <- membership(wc)

net_stat <- asNetwork(net)
png("figs/network1.png", res = 600,  width = 5000 , height = 5000, units="px")
set.seed(11)
par(mar=c(0,0,0,0))
plot.network(net_stat, vertex.cex= 0.05 + 0.25*log(graph.strength(net)), label =ifelse(degree(net)>100,V(net)$name,NA), label.bg = "white", label.col = "black", edge.col = "lightgray", edge.lty = 0.5, label.cex = 0.6,  displaylabels = TRUE, vertex.col = membership(wc), jitter = T, edge.len = 0.2, boxed.labels=T, label.border=1, pad=5)
dev.off()
```

![](figs/network1.png){fig-align="center"}

```{r}
#| warning: false
library(networkD3)


wc <- cluster_walktrap(net)
members <- membership(wc)
net2 <- igraph_to_networkD3(net, group = members)
forceNetwork(Links = net2$links, Nodes = net2$nodes, 
             Source = 'source', Target = 'target', 
             NodeID = 'name', Group = 'group') |> 
  saveNetwork(file = 'figs/net.html')



```

```{r}
# create a csv file of the network
write_csv(as_long_data_frame(net), file = "rede.csv")



```

# Data characteristics

## Source

```{r}
p2 <- dat %>% 
  filter(article_type == "Original Article") %>% 
  tabyl(data_source) %>% 
  ggplot(aes(reorder(data_source, -n), n, fill = n))+
  geom_col(fill = "#ACA4E2", width = 0.56)+
  geom_text(
    aes(x = data_source, y = n, label = n),
    position = position_dodge(width = 1),
    vjust = -0.5, size = 4) + 
  theme(legend.position = "bottom",
          panel.grid.major=element_line(colour="grey94"))+
scale_y_continuous(breaks = c(0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30))+
  labs(x = "Source of the data used in the analysis", y = "Number of original articles")
 p2
 ggsave("figs/figure2.png", width =8, height = 6, bg = "white")

```

## Systematic review in PR?

```{r}

dat |> 
  tabyl(systematic_review, data_source)

```

## PRISM diagram?

```{r}

dat |> 
  tabyl(sr_flow_diag)

```

## Shared?

```{r}
dat |> 
  tabyl(data_shared)
```

# Study characteristics

## Number of trials

```{r}
#| warning: false
dat |> 
  count(n_trials_total) |> 
  ggplot(aes(n_trials_total))+
  geom_histogram(color = "white")

dat |> 
  count(n_trials_total) |> 
  summary()
```

## By objective and product type

```{r}
objective <- dat %>% 
  filter(article_type == "Original Article") %>% 
  tabyl(objective) |> 
  select(-percent)

type <- dat %>% 
  filter(article_type == "Original Article") %>% 
  filter(objective == "Product effects") %>% 
  tabyl(product_type) |> 
  select(-percent)
cbind(objective, type)

```

## Response variables

```{r}
tab <- dat %>% 
  dplyr::select(response1 , response2, response3, response4, response5) %>% 
  pivot_longer(names_to = "type", values_to = "Variable", 1:5) %>% 
  select(Variable) %>%
    filter(Variable != "NA") %>% 
  tabyl(Variable) %>% 
  select(-percent)
nrow(tab)
tab

library(wordcloud)
wordcloud(words = tab$Variable, freq = tab$n,  min.freq = 1,           max.words=200, random.order=FALSE, rot.per=0.25,            colors=brewer.pal(5, "Dark2"))


```

## Number of responses per study

```{r}
dat |> 
  tabyl(n_responses)
```

# Meta-analysis model characteristics

## Effect sizes

```{r}
dat %>% 
  dplyr::select(effect_size_1, effect_size_2, effect_size_3, effect_size_4, effect_size_5) %>% 
  pivot_longer(names_to = "type", values_to = "value", 1:5) %>% 
  select(value) %>%
    filter(value != "NA") %>% 
  tabyl(value) |> 
  adorn_totals()
```

## Effect-size by common response variable

```{r}
es <- dat %>% 
  dplyr::select(code, effect_size_1, effect_size_2, effect_size_3, effect_size_4, effect_size_5) %>% 
  pivot_longer(names_to = "type", values_to = "value", 2:6)

rv <- dat %>% 
  dplyr::select(code, response1 , response2, response3, response4, response5) %>% 
  pivot_longer(names_to = "type", values_to = "Variable", 2:6)

rv

left_join(es, rv, by = "code") |> 
  select(Variable, value) |> 
  filter(Variable %in% c("severity", "incidence",  "yield", "index", "slope", "intercept")) |> 
  tabyl(value, Variable)
```

## Sampling variance

```{r}
dat |> 
  tabyl(sampling_var)

```

## Heterogeneity test

```{r}
dat |> 
  tabyl(`Heterogenity test`)
```

## General approach

```{r}
 
dat |> 
  tabyl(ma_approach)
```

## MA basic model

```{r}
dat |> 
  tabyl(ma_model)
```

## MA model n. of effects

```{r}
dat |> 
  tabyl(ma_model_2)
```

## Number of variables

```{r}
dat |> 
  tabyl(ma_n_variables)
```

## Moderator analysis?

```{r}
dat |> 
  tabyl(moderator)

dat |> 
  tabyl(moderator_model)
```

# Software characteristics

## General software

```{r}
dat |> 
  tabyl(general_software)
```

```{r}
dat |> 
  tabyl(MA_software)
```

# Data summary

## Results in table?

```{r}
dat |> 
  tabyl(res_table)
```

## Results in plot for raw data

```{r}
dat |> 
  tabyl(res_plot_raw)
```

## Result in forest plot

```{r}
dat |> 
  tabyl(res_forest)
```

# Economic analysis

```{r}
dat |> 
  tabyl(econ_analysis)
```
